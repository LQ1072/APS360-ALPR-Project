# -*- coding: utf-8 -*-
"""aps360_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dXSpn57bv8JTiE7LVTxSWU8hAKXdS6II?usp=sharing
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required packages
!pip install ultralytics

import os
import shutil
import torch
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Define base directory
BASE_DIR = '/content/drive/My Drive/License Plates.v3-original-license-plates.darknet'
ORGANIZED_DIR = '/content/dataset'

def organize_dataset():
    """Organize dataset into YOLOv8 format structure."""
    print("Organizing dataset...")

    # Create necessary directories
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(ORGANIZED_DIR, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(ORGANIZED_DIR, split, 'labels'), exist_ok=True)

        # Source directory
        src_dir = os.path.join(BASE_DIR, split)

        # Copy and organize files
        for filename in os.listdir(src_dir):
            src_path = os.path.join(src_dir, filename)

            # Skip if it's the labels file
            if filename == 'darknet.labels':
                continue

            if filename.endswith(('.jpg', '.jpeg', '.png')):
                # Copy image
                dst_path = os.path.join(ORGANIZED_DIR, split, 'images', filename)
                shutil.copy2(src_path, dst_path)
            elif filename.endswith('.txt'):
                # Copy label
                dst_path = os.path.join(ORGANIZED_DIR, split, 'labels', filename)
                shutil.copy2(src_path, dst_path)

    print("Dataset organization completed!")

def create_dataset_yaml():
    """Create YAML configuration file for the dataset."""
    yaml_content = f"""
path: {ORGANIZED_DIR}  # dataset root dir
train: train/images  # train images
val: valid/images  # val images
test: test/images  # test images

# Classes
nc: 2  # number of classes
names: ['license_plate', 'vehicle']  # class names
"""

    with open('dataset.yaml', 'w') as f:
        f.write(yaml_content)
    print("dataset.yaml created successfully")

def train_model():
    """Train YOLOv8 model with GPU acceleration."""
    # Load YOLOv8 model
    model = YOLO('yolov8n.pt')

    # Train the model with GPU settings
    results = model.train(
        data='dataset.yaml',
        epochs=50,
        imgsz=640,
        batch=32,  # Increased batch size for GPU
        patience=10,
        optimizer='AdamW',
        lr0=0.001,
        lrf=0.01,
        momentum=0.937,
        weight_decay=0.0005,
        warmup_epochs=3,
        box=7.5,
        cls=0.5,
        workers=8,  # Increase workers for faster data loading
        amp=True   # Enable mixed precision training
    )
    return model



def verify_organized_dataset():
    """Verify the organized dataset structure."""
    for split in ['train', 'valid', 'test']:
        images_dir = os.path.join(ORGANIZED_DIR, split, 'images')
        labels_dir = os.path.join(ORGANIZED_DIR, split, 'labels')

        n_images = len([f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])
        n_labels = len([f for f in os.listdir(labels_dir) if f.endswith('.txt')])

        print(f"\n{split} split:")
        print(f"Images: {n_images}")
        print(f"Labels: {n_labels}")

if __name__ == "__main__":
  # Start training
    print(f"Starting training on device: {'cuda' if torch.cuda.is_available() else 'cpu'}")
    # Organize dataset
    print("Step 1: Organizing dataset...")
    organize_dataset()

    # Verify organization
    print("\nStep 2: Verifying dataset organization...")
    verify_organized_dataset()

    # Create YAML config
    print("\nStep 3: Creating dataset configuration...")
    create_dataset_yaml()

    # Start training
    print("\nStep 4: Starting model training...")
    model = train_model()

    print("\nTraining completed!")

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import numpy as np
import os
from pathlib import Path
import pandas as pd

# Load the best trained model
model = YOLO('runs/detect/train/weights/best.pt')

def plot_batch_results(image_paths, model, title):
    """Plot detection results for a batch of images"""
    fig = plt.figure(figsize=(20, 10))
    for idx, img_path in enumerate(image_paths, 1):
        # Predict
        results = model(img_path)[0]

        # Get image
        img = cv2.imread(str(img_path))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Create subplot
        if idx <= 6:  # Only plot up to 6 images
            plt.subplot(2, 3, idx)
            plt.imshow(img)

            # Plot boxes
            boxes = results.boxes
            for box, conf in zip(boxes.xyxy, boxes.conf):
                x1, y1, x2, y2 = box.cpu().numpy()

                # Draw rectangle
                plt.gca().add_patch(plt.Rectangle(
                    (x1, y1), x2-x1, y2-y1,
                    fill=False, color='red', linewidth=2
                ))

                # Add confidence score
                plt.text(
                    x1, y1-10,
                    f'Conf: {conf:.2f}',
                    color='red',
                    fontsize=8,
                    bbox=dict(facecolor='white', alpha=0.8)
                )

            plt.title(f'Image {idx}')
            plt.axis('off')

    plt.suptitle(title, fontsize=16)
    plt.tight_layout()
    plt.show()

# Evaluate on validation set
print("\nEvaluating on validation set...")
val_results = model.val(data='dataset.yaml')

# Print results properly handling numpy arrays
print("\nValidation Results:")
print(f"mAP50: {float(val_results.box.map50):.3f}")
print(f"mAP50-95: {float(val_results.box.map):.3f}")

# Plot validation results
print("\nPlotting validation examples...")
val_images = list(Path('/content/dataset/valid/images').glob('*.jpg'))
val_sample = np.random.choice(val_images, min(6, len(val_images)), replace=False)
plot_batch_results(val_sample, model, "Validation Set Results")

# Plot test results
print("\nPlotting test examples...")
test_images = list(Path('/content/dataset/test/images').glob('*.jpg'))
test_sample = np.random.choice(test_images, min(6, len(test_images)), replace=False)
plot_batch_results(test_sample, model, "Test Set Results")

# Plot training metrics
results_file = Path('runs/detect/train/results.csv')
if results_file.exists():
    results = pd.read_csv(results_file)

    plt.figure(figsize=(15, 5))

    # Plot mAP
    plt.subplot(1, 3, 1)
    plt.plot(results['epoch'], results['metrics/mAP50'], label='mAP50')
    plt.plot(results['epoch'], results['metrics/mAP50-95'], label='mAP50-95')
    plt.xlabel('Epoch')
    plt.ylabel('mAP')
    plt.title('Mean Average Precision')
    plt.legend()
    plt.grid(True)

    # Plot Precision-Recall
    plt.subplot(1, 3, 2)
    plt.plot(results['epoch'], results['metrics/precision'], label='Precision')
    plt.plot(results['epoch'], results['metrics/recall'], label='Recall')
    plt.xlabel('Epoch')
    plt.ylabel('Value')
    plt.title('Precision and Recall')
    plt.legend()
    plt.grid(True)

    # Plot Losses
    plt.subplot(1, 3, 3)
    plt.plot(results['epoch'], results['train/box_loss'], label='Box Loss')
    plt.plot(results['epoch'], results['train/cls_loss'], label='Class Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Losses')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Print final model statistics
print("\nModel Performance Summary:")
print("-" * 50)
print(f"Best mAP50: {float(val_results.box.map50):.3f}")
print(f"Best mAP50-95: {float(val_results.box.map):.3f}")
print("-" * 50)

import os
from ultralytics import YOLO
import cv2
import numpy as np
from pathlib import Path
import torch

def train_enhanced_model():
    """Train model with enhanced focus on license plates."""
    # Load YOLOv8 model
    model = YOLO('yolov8n.pt')

    # Train with enhanced parameters
    results = model.train(
        data='dataset.yaml',
        epochs=100,  # More epochs
        imgsz=1280,  # Higher resolution
        batch=16,    # Smaller batch size for better learning
        patience=20,
        conf=0.1,    # Lower confidence threshold
        iou=0.3,     # Lower IoU threshold for more detections
        max_det=3,   # Allow multiple detections
        classes=None, # Keep both classes but focus on plates
        box=10.0,    # Increased box loss weight
        cls=0.7,     # Adjusted class loss weight
        device=0,
        workers=8,
        amp=True,
        # Data augmentation parameters
        augment=True,
        mosaic=1.0,
        degrees=20.0,
        translate=0.2,
        scale=0.9,
        shear=10.0,
        perspective=0.001,
        flipud=0.5,
        fliplr=0.5,
        hsv_h=0.015,
        hsv_s=0.7,
        hsv_v=0.4,
        copy_paste=0.1,
        mixup=0.1
    )
    return model

def enhance_annotations(dataset_path):
    """Enhance license plate annotations by adjusting their box sizes."""
    for split in ['train', 'valid', 'test']:
        labels_dir = Path(dataset_path) / split / 'labels'
        for label_file in labels_dir.glob('*.txt'):
            with open(label_file, 'r') as f:
                lines = f.readlines()

            enhanced_lines = []
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    if class_id == 0:  # License plate
                        # Slightly expand the box for better detection
                        x, y, w, h = map(float, parts[1:5])
                        w *= 1.1  # Make box slightly wider
                        h *= 1.1  # Make box slightly taller
                        # Ensure values stay normalized
                        w = min(w, 1.0)
                        h = min(h, 1.0)
                        enhanced_lines.append(f"0 {x} {y} {w} {h}\n")
                    else:
                        enhanced_lines.append(line)

            # Write enhanced annotations
            with open(label_file, 'w') as f:
                f.writelines(enhanced_lines)

# Main execution
if __name__ == "__main__":
    print("Enhancing annotations...")
    enhance_annotations('/content/dataset')

    print("\nStarting enhanced training...")
    model = train_enhanced_model()

    print("\nEvaluating model...")
    model.val()

    # Test predictions
    test_images = list(Path('/content/dataset/test/images').glob('*.jpg'))
    results = model(test_images, conf=0.3, iou=0.3)

    # Visualize results
    plt.figure(figsize=(20, 10))
    for idx, (img_path, result) in enumerate(zip(test_images[:6], results), 1):
        img = cv2.imread(str(img_path))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        plt.subplot(2, 3, idx)
        plt.imshow(img)

        # Draw detections
        boxes = result.boxes
        for box, conf, cls in zip(boxes.xyxy, boxes.conf, boxes.cls):
            x1, y1, x2, y2 = box.cpu().numpy()
            color = 'red' if cls == 0 else 'blue'
            label = 'Plate' if cls == 0 else 'Vehicle'

            plt.gca().add_patch(plt.Rectangle(
                (x1, y1), x2-x1, y2-y1,
                fill=False, color=color, linewidth=2
            ))

            plt.text(
                x1, y1-5,
                f'{label}: {conf:.2f}',
                color=color,
                fontsize=8,
                bbox=dict(facecolor='white', alpha=0.8)
            )

        plt.title(f'Image {idx}')
        plt.axis('off')

    plt.suptitle('Enhanced License Plate Detection', fontsize=16)
    plt.tight_layout()
    plt.show()

import os
from pathlib import Path

def filter_large_boxes(dataset_path, size_threshold=0.1):
    """
    Filter out bounding boxes larger than the threshold.

    Args:
        dataset_path: Path to dataset root
        size_threshold: Maximum allowed box area relative to image (0.1 = 10% of image area)
    """
    total_filtered = 0
    total_kept = 0

    for split in ['train', 'valid', 'test']:
        labels_dir = Path(dataset_path) / split / 'labels'
        print(f"\nProcessing {split} split...")

        for label_file in labels_dir.glob('*.txt'):
            with open(label_file, 'r') as f:
                lines = f.readlines()

            # Filter boxes
            filtered_lines = []
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    # Get width and height (normalized)
                    w, h = float(parts[3]), float(parts[4])
                    # Calculate box area (normalized)
                    area = w * h

                    # Keep only small boxes
                    if area <= size_threshold:
                        filtered_lines.append(line)
                        total_kept += 1
                    else:
                        total_filtered += 1

            # Write back filtered annotations
            with open(label_file, 'w') as f:
                f.writelines(filtered_lines)

    print(f"\nFiltering complete:")
    print(f"Total boxes kept: {total_kept}")
    print(f"Total boxes filtered out: {total_filtered}")
    print(f"Percentage kept: {(total_kept/(total_kept+total_filtered))*100:.1f}%")

# Filter the annotations
dataset_path = '/content/dataset'
print("Filtering out large bounding boxes...")
filter_large_boxes(dataset_path, size_threshold=0.1)  # 10% threshold

# Train model with original settings
def train_model():
    model = YOLO('yolov8n.pt')

    results = model.train(
        data='dataset.yaml',
        epochs=50,
        imgsz=640,
        batch=32,
        patience=10,
        optimizer='AdamW',
        lr0=0.001,
        lrf=0.01,
        momentum=0.937,
        weight_decay=0.0005,
        warmup_epochs=3,
        box=7.5,
        cls=0.5,
        device=0,
        workers=8,
        amp=True
    )
    return model

print("\nStarting training with filtered annotations...")
model = train_model()

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# # Generate the en_US.UTF-8 locale
# sudo locale-gen en_US.UTF-8
# 
# # Update locale settings
# sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8
# 
# # Export locale variables for the current shell session
# export LC_ALL=en_US.UTF-8
# export LANG=en_US.UTF-8
# export LANGUAGE=en_US.UTF-8
# 
# # Verify the locale settings
# locale
# 
#

import locale

# Get the current locale
current_locale = locale.getlocale()
print(f"Current locale: {current_locale}")

# Get the preferred encoding
preferred_encoding = locale.getpreferredencoding()
print(f"Preferred encoding: {preferred_encoding}")

import os

# Set locale environment variables
os.environ['LC_ALL'] = 'en_US.UTF-8'
os.environ['LANG'] = 'en_US.UTF-8'
os.environ['LANGUAGE'] = 'en_US.UTF-8'

# Verify the environment variables
print(f"Environment LC_ALL: {os.environ.get('LC_ALL')}")
print(f"Environment LANG: {os.environ.get('LANG')}")
print(f"Environment LANGUAGE: {os.environ.get('LANGUAGE')}")

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# # Update package lists
# apt update
# 
# # Install software-properties-common
# apt install -y software-properties-common
# 
# # Add the Tesseract PPA
# add-apt-repository -y ppa:alex-p/tesseract-ocr
# 
# # Update package lists again after adding the new repository
# apt update
# 
# # Install Tesseract OCR
# apt install -y tesseract-ocr
# 
# # Install pytesseract via pip
# pip install pytesseract
#

# # Import necessary libraries
# from ultralytics import YOLO
# import cv2
# import matplotlib.pyplot as plt
# from pathlib import Path
# import numpy as np

# # Load the best trained model
# model = YOLO('runs/detect/train3/weights/best.pt')

# # Function to visualize detections
# def visualize_detections(model, test_dir, num_images=6, conf_threshold=0.25):
#     """
#     Visualize detection results from the model.

#     Args:
#         model: Trained YOLO model
#         test_dir: Directory containing test images
#         num_images: Number of images to visualize
#         conf_threshold: Confidence threshold for detections
#     """
#     # Get test images
#     test_images = list(Path(test_dir).glob('*.jpg'))
#     np.random.shuffle(test_images)

#     # Create subplot grid
#     plt.figure(figsize=(20, 10))

#     for idx, img_path in enumerate(test_images[:num_images]):
#         # Run inference
#         results = model.predict(str(img_path), conf=conf_threshold)[0]

#         # Get image
#         img = cv2.imread(str(img_path))
#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

#         # Create subplot
#         plt.subplot(2, 3, idx + 1)
#         plt.imshow(img)

#         # Draw boxes and scores
#         boxes = results.boxes
#         for box, conf in zip(boxes.xyxy, boxes.conf):
#             x1, y1, x2, y2 = box.cpu().numpy()

#             # Draw rectangle
#             plt.gca().add_patch(plt.Rectangle(
#                 (x1, y1), x2-x1, y2-y1,
#                 fill=False, color='red', linewidth=2
#             ))

#             # Add confidence score
#             plt.text(
#                 x1, y1-10,
#                 f'Conf: {conf:.2f}',
#                 color='red',
#                 fontsize=8,
#                 bbox=dict(facecolor='white', alpha=0.8)
#             )

#         plt.title(f'Image {idx+1}')
#         plt.axis('off')

#     plt.suptitle('Test Set Results', fontsize=16)
#     plt.tight_layout()
#     plt.show()

# Run visualization
test_dir = '/content/dataset/test/images'
# print("Visualizing test results...")
# visualize_detections(model, test_dir, num_images=6, conf_threshold=0.25)

# # Print model performance metrics
# print("\nModel Performance Metrics:")
# metrics = model.val(data='dataset.yaml', split='test')
# print(f"mAP50: {metrics.box.map50:.3f}")
# print(f"mAP50-95: {metrics.box.map:.3f}")\



def visualize_detections(model, test_dir, num_images=35, conf_threshold=0.25):
    test_images = list(Path(test_dir).glob('*.jpg'))
    np.random.shuffle(test_images)

    plt.figure(figsize=(40, 25))

    for idx, img_path in enumerate(test_images[:num_images]):
        results = model.predict(str(img_path), conf=conf_threshold)[0]
        img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)

        plt.subplot(10, 5, idx + 1)
        plt.imshow(img)

        for box, conf in zip(results.boxes.xyxy, results.boxes.conf):
            x1, y1, x2, y2 = box.cpu().numpy()
            plt.gca().add_patch(plt.Rectangle(
                (x1, y1), x2-x1, y2-y1,
                fill=False, color='red', linewidth=2
            ))
            plt.text(x1, y1-10, f'Conf: {conf:.2f}',
                    color='red', fontsize=6,
                    bbox=dict(facecolor='white', alpha=0.8))

        plt.title(f'Image {idx+1}', fontsize=8)
        plt.axis('off')

    plt.suptitle('Test Set Results', fontsize=16)
    plt.tight_layout()
    plt.show()

visualize_detections(model, test_dir, num_images=5)

def visualize_detections(model, test_dir, num_images=35, conf_threshold=0.25):
    test_images = list(Path(test_dir).glob('*.jpg'))
    np.random.shuffle(test_images)

    plt.figure(figsize=(40, 25))

    for idx, img_path in enumerate(test_images[:num_images]):
        results = model.predict(str(img_path), conf=conf_threshold)[0]
        img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)

        plt.subplot(10, 5, idx + 1)
        plt.imshow(img)

        for box, conf in zip(results.boxes.xyxy, results.boxes.conf):
            x1, y1, x2, y2 = box.cpu().numpy()
            plt.gca().add_patch(plt.Rectangle(
                (x1, y1), x2-x1, y2-y1,
                fill=False, color='red', linewidth=2
            ))
            plt.text(x1, y1-10, f'Conf: {conf:.2f}',
                    color='red', fontsize=6,
                    bbox=dict(facecolor='white', alpha=0.8))

        plt.title(f'Image {idx+1}', fontsize=8)
        plt.axis('off')

    plt.suptitle('Test Set Results', fontsize=16)
    plt.tight_layout()
    plt.show()

visualize_detections(model, '/content/drive/MyDrive/License Plate Recognition.v4-resized640_aug3x-accurate.yolov8', num_images=5)

from ultralytics import YOLO
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pytesseract
from pathlib import Path
import easyocr

import os
from paddleocr import PaddleOCR

# Initialize EasyOCR
reader_easyocr = easyocr.Reader(['en'])

# Initialize PaddleOCR
reader_paddle = PaddleOCR(lang='en', use_angle_cls=True, rec=True, cls=True)

def preprocess_plate(plate_img):
    """
    Preprocess the license plate image for better OCR.
    """
    # Convert to grayscale
    gray = cv2.cvtColor(plate_img, cv2.COLOR_RGB2GRAY)

    # Apply Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (1, 1), 0)

    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    clahe_img = clahe.apply(blurred)

    # Thresholding to get black text on white background
    _, threshold = cv2.threshold(clahe_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Increase image size for better OCR
    scaled = cv2.resize(threshold, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    # scaled = cv2.resize(blurred, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)

    return scaled

def read_license_plate(model, image_path, conf_threshold=0.25, ocr_conf_threshold=0.5):
    """
    Detect and read license plate from an image using EasyOCR, Tesseract, and PaddleOCR as fallbacks.

    Parameters:
    - model: The YOLO model for license plate detection.
    - image_path: Path to the image file.
    - conf_threshold: Confidence threshold for YOLO detections.
    - ocr_conf_threshold: Confidence threshold for EasyOCR results.

    Returns:
    - text: Detected license plate text or 'UNKNOWN' if all OCR methods fail.
    - plate_img: The cropped license plate image.
    - processed_plate: The preprocessed plate image used for OCR.
    """
    # Read image
    img = cv2.imread(str(image_path))
    if img is None:
        print(f"Error: Unable to read image at {image_path}")
        return "UNKNOWN", None, None
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Detect license plate
    results = model.predict(img_rgb, conf=conf_threshold)[0]

    # Check if any detections are made
    if len(results.boxes) == 0:
        return "UNKNOWN", None, None

    # Extract boxes and confidences
    boxes = results.boxes.xyxy.cpu().numpy()
    confidences = results.boxes.conf.cpu().numpy()
    best_idx = np.argmax(confidences)

    # Get the best box
    box = boxes[best_idx].astype(int)
    conf = confidences[best_idx]

    # Crop license plate with boundary checks
    x1, y1, x2, y2 = box
    x1 = max(x1, 0)
    y1 = max(y1, 0)
    x2 = min(x2, img_rgb.shape[1])
    y2 = min(y2, img_rgb.shape[0])
    plate_img = img_rgb[y1:y2, x1:x2]

    if plate_img.size == 0:
        print(f"Warning: Cropped plate image is empty for {image_path}")
        return "UNKNOWN", plate_img, None

    # Preprocess the plate image
    processed_plate = preprocess_plate(plate_img)

    # Initialize detected text
    text = ''

    # Attempt OCR with EasyOCR
    try:
        ocr_results_easyocr = reader_easyocr.readtext(processed_plate)
        easyocr_text = ' '.join([r[1] for r in ocr_results_easyocr if r[2] >= ocr_conf_threshold])
        easyocr_text_clean = ''.join(c for c in easyocr_text if c.isalnum())
        if easyocr_text_clean:
            text = easyocr_text_clean
            print("OCR Engine Used: EasyOCR")
    except Exception as e:
        print(f"EasyOCR Error: {e}")

    # If EasyOCR fails, fallback to Tesseract
    if not text:
        try:
            custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
            tesseract_text = pytesseract.image_to_string(processed_plate, config=custom_config)
            tesseract_text_clean = ''.join(c for c in tesseract_text if c.isalnum())
            if tesseract_text_clean:
                text = tesseract_text_clean
                print("OCR Engine Used: Tesseract")
        except Exception as e:
            print(f"Tesseract OCR Error: {e}")

    # If both EasyOCR and Tesseract fail, fallback to PaddleOCR
    if not text:
        try:
            ocr_results_paddle = reader_paddle.ocr(processed_plate, rec=True, cls=True)
            paddle_text = ' '.join([line[1][0] for line in ocr_results_paddle if line[1][1] >= ocr_conf_threshold])
            paddle_text_clean = ''.join(c for c in paddle_text if c.isalnum())
            if paddle_text_clean:
                text = paddle_text_clean
                print("OCR Engine Used: PaddleOCR")
        except Exception as e:
            print(f"PaddleOCR Error: {e}")

    # If all OCR methods fail, return 'UNKNOWN'
    if not text:
        text = "UNKNOWN"
        print("OCR Failed: Returning 'UNKNOWN'")

    return text, plate_img, processed_plate


def visualize_results(image_path, text, original_plate, processed_plate):
    """
    Visualize original image, cropped plate, processed plate, and OCR result.
    """
    plt.figure(figsize=(15, 4))

    # Original image with plate
    plt.subplot(141)
    img = cv2.imread(str(image_path))
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(img_rgb)
    plt.title('Original Image')
    plt.axis('off')

    # Cropped plate
    plt.subplot(142)
    plt.imshow(original_plate)
    plt.title('Cropped Plate')
    plt.axis('off')

    # Processed plate
    plt.subplot(143)
    plt.imshow(processed_plate, cmap='gray')
    plt.title('Processed Plate')
    plt.axis('off')

    # Text result
    plt.subplot(144)
    plt.text(0.5, 0.5, f'Detected Text:\n{text}',
             ha='center', va='center', fontsize=12,
             bbox=dict(facecolor='white', alpha=0.8))
    plt.axis('off')

    plt.tight_layout()
    plt.show()

# Main execution
if __name__ == "__main__":
    # Load model
    model = YOLO('runs/detect/train5/weights/best.pt')

    # Get test images
    test_dir = Path('/content/dataset/test/images')
    test_images = list(test_dir.glob('*.jpg'))

    # Process random sample of images
    for img_path in np.random.choice(test_images, 20):
        print(f"\nProcessing {img_path.name}")

        # Detect and read plate
        text, plate_img, processed_plate = read_license_plate(model, img_path)

        if text is not None:
            print(f"Detected Text: {text}")
            # Visualize results
            visualize_results(img_path, text, plate_img, processed_plate)
        else:
            print("No license plate detected")

from ultralytics import YOLO
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pytesseract
from pathlib import Path
import easyocr

import os
from paddleocr import PaddleOCR

# Initialize EasyOCR
reader_easyocr = easyocr.Reader(['en'])

# Initialize PaddleOCR
reader_paddle = PaddleOCR(lang='en', use_angle_cls=True, rec=True, cls=True)

def preprocess_plate(plate_img):
    """
    Preprocess the license plate image for better OCR.
    """
    # Convert to grayscale
    gray = cv2.cvtColor(plate_img, cv2.COLOR_RGB2GRAY)

    # Apply Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (1, 1), 0)

    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    clahe_img = clahe.apply(blurred)

    # Thresholding to get black text on white background
    _, threshold = cv2.threshold(clahe_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Increase image size for better OCR
    scaled = cv2.resize(threshold, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    # scaled = cv2.resize(blurred, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)

    return scaled

def read_license_plate(model, image_path, conf_threshold=0.25, ocr_conf_threshold=0.5):
    """
    Detect and read license plate from an image using EasyOCR, Tesseract, and PaddleOCR as fallbacks.

    Parameters:
    - model: The YOLO model for license plate detection.
    - image_path: Path to the image file.
    - conf_threshold: Confidence threshold for YOLO detections.
    - ocr_conf_threshold: Confidence threshold for EasyOCR results.

    Returns:
    - text: Detected license plate text or 'UNKNOWN' if all OCR methods fail.
    - plate_img: The cropped license plate image.
    - processed_plate: The preprocessed plate image used for OCR.
    """
    # Read image
    img = cv2.imread(str(image_path))
    if img is None:
        print(f"Error: Unable to read image at {image_path}")
        return "UNKNOWN", None, None
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Detect license plate
    results = model.predict(img_rgb, conf=conf_threshold)[0]

    # Check if any detections are made
    if len(results.boxes) == 0:
        return "UNKNOWN", None, None

    # Extract boxes and confidences
    boxes = results.boxes.xyxy.cpu().numpy()
    confidences = results.boxes.conf.cpu().numpy()
    best_idx = np.argmax(confidences)

    # Get the best box
    box = boxes[best_idx].astype(int)
    conf = confidences[best_idx]

    # Crop license plate with boundary checks
    x1, y1, x2, y2 = box
    x1 = max(x1, 0)
    y1 = max(y1, 0)
    x2 = min(x2, img_rgb.shape[1])
    y2 = min(y2, img_rgb.shape[0])
    plate_img = img_rgb[y1:y2, x1:x2]

    if plate_img.size == 0:
        print(f"Warning: Cropped plate image is empty for {image_path}")
        return "UNKNOWN", plate_img, None

    # Preprocess the plate image
    processed_plate = preprocess_plate(plate_img)

    # Initialize detected text
    text = ''

    # Attempt OCR with EasyOCR
    try:
        ocr_results_easyocr = reader_easyocr.readtext(processed_plate)
        easyocr_text = ' '.join([r[1] for r in ocr_results_easyocr if r[2] >= ocr_conf_threshold])
        easyocr_text_clean = ''.join(c for c in easyocr_text if c.isalnum())
        if easyocr_text_clean:
            text = easyocr_text_clean
            print("OCR Engine Used: EasyOCR")
    except Exception as e:
        print(f"EasyOCR Error: {e}")

    # If EasyOCR fails, fallback to Tesseract
    if not text:
        try:
            custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
            tesseract_text = pytesseract.image_to_string(processed_plate, config=custom_config)
            tesseract_text_clean = ''.join(c for c in tesseract_text if c.isalnum())
            if tesseract_text_clean:
                text = tesseract_text_clean
                print("OCR Engine Used: Tesseract")
        except Exception as e:
            print(f"Tesseract OCR Error: {e}")

    # If both EasyOCR and Tesseract fail, fallback to PaddleOCR
    if not text:
        try:
            ocr_results_paddle = reader_paddle.ocr(processed_plate, rec=True, cls=True)
            paddle_text = ' '.join([line[1][0] for line in ocr_results_paddle if line[1][1] >= ocr_conf_threshold])
            paddle_text_clean = ''.join(c for c in paddle_text if c.isalnum())
            if paddle_text_clean:
                text = paddle_text_clean
                print("OCR Engine Used: PaddleOCR")
        except Exception as e:
            print(f"PaddleOCR Error: {e}")

    # If all OCR methods fail, return 'UNKNOWN'
    if not text:
        text = "UNKNOWN"
        print("OCR Failed: Returning 'UNKNOWN'")

    return text, plate_img, processed_plate


def visualize_results(image_path, text, original_plate, processed_plate):
    """
    Visualize original image, cropped plate, processed plate, and OCR result.
    """
    plt.figure(figsize=(15, 4))

    # Original image with plate
    plt.subplot(141)
    img = cv2.imread(str(image_path))
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(img_rgb)
    plt.title('Original Image')
    plt.axis('off')

    # Cropped plate
    plt.subplot(142)
    plt.imshow(original_plate)
    plt.title('Cropped Plate')
    plt.axis('off')

    # Processed plate
    plt.subplot(143)
    plt.imshow(processed_plate, cmap='gray')
    plt.title('Processed Plate')
    plt.axis('off')

    # Text result
    plt.subplot(144)
    plt.text(0.5, 0.5, f'Detected Text:\n{text}',
             ha='center', va='center', fontsize=12,
             bbox=dict(facecolor='white', alpha=0.8))
    plt.axis('off')

    plt.tight_layout()
    plt.show()

# Main execution
if __name__ == "__main__":
    # Load model
    model = YOLO('runs/detect/train5/weights/best.pt')

    # Get test images
    test_dir = Path('/content/drive/MyDrive/License Plate Recognition.v4-resized640_aug3x-accurate.yolov8')
    test_images = list(test_dir.glob('*.jpg'))

    # Process random sample of images
    for img_path in np.random.choice(test_images, 20):
        print(f"\nProcessing {img_path.name}")

        # Detect and read plate
        text, plate_img, processed_plate = read_license_plate(model, img_path)

        if text is not None:
            print(f"Detected Text: {text}")
            # Visualize results
            visualize_results(img_path, text, plate_img, processed_plate)
        else:
            print("No license plate detected")

# Install EasyOCR
!pip install easyocr

!pip install paddlepaddle paddleocr

import easyocr
import cv2
import matplotlib.pyplot as plt
import os
from pathlib import Path

# Initialize EasyOCR
reader = easyocr.Reader(['en'])

def process_images():
    model = YOLO('runs/detect/train5/weights/best.pt')
    test_dir = '/content/dataset/test/images'
    labels_dir = '/content/dataset/test/labels'

    # Process images in test directory
    image_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]

    for img_file in image_files:
        image_path = os.path.join(test_dir, img_file)
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Get predictions
        results = model(image_rgb)[0]
        boxes = results.boxes.xyxy.cpu().numpy()

        for box in boxes:
            x1, y1, x2, y2 = map(int, box[:4])
            plate_img = image_rgb[y1:y2, x1:x2]

            # OCR
            result = reader.readtext(plate_img)
            text = ' '.join([r[1] for r in result if r[2] > 0.5])

            # Draw results
            cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image_rgb, text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX,
                       0.9, (0, 255, 0), 2, cv2.LINE_AA)

        plt.figure(figsize=(10, 10))
        plt.imshow(image_rgb)
        plt.title(f"Image: {img_file}")
        plt.axis('off')
        plt.show()

        print(f"Processed {img_file}")

process_images()

def visualize_detections(model, test_dir, num_images=35, conf_threshold=0.25):
    test_images = list(Path(test_dir).glob('*.jpg'))
    np.random.shuffle(test_images)

    plt.figure(figsize=(40, 25))

    for idx, img_path in enumerate(test_images[:num_images]):
        results = model.predict(str(img_path), conf=conf_threshold)[0]
        img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)

        plt.subplot(10, 5, idx + 1)
        plt.imshow(img)

        for box, conf in zip(results.boxes.xyxy, results.boxes.conf):
            x1, y1, x2, y2 = box.cpu().numpy()
            plt.gca().add_patch(plt.Rectangle(
                (x1, y1), x2-x1, y2-y1,
                fill=False, color='red', linewidth=2
            ))
            plt.text(x1, y1-10, f'Conf: {conf:.2f}',
                    color='red', fontsize=12,
                    bbox=dict(facecolor='white', alpha=0.8))

        plt.title(f'Image {idx+1}', fontsize=8)
        plt.axis('off')

    plt.suptitle('Test Set Results', fontsize=16)
    plt.show()

visualize_detections(model, '/content/drive/MyDrive/License Plates.v3-original-license-plates-test.darknet', num_images=5)

from ultralytics import YOLO
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pytesseract
from pathlib import Path
import easyocr

import os
from paddleocr import PaddleOCR

# Initialize EasyOCR
reader_easyocr = easyocr.Reader(['en'])

# Initialize PaddleOCR
reader_paddle = PaddleOCR(lang='en', use_angle_cls=True, rec=True, cls=True)

def preprocess_plate(plate_img):
    """
    Preprocess the license plate image for better OCR.
    """
    # Convert to grayscale
    gray = cv2.cvtColor(plate_img, cv2.COLOR_RGB2GRAY)

    # Apply Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (1, 1), 0)

    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    clahe_img = clahe.apply(blurred)

    # Thresholding to get black text on white background
    _, threshold = cv2.threshold(clahe_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Increase image size for better OCR
    scaled = cv2.resize(threshold, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    # scaled = cv2.resize(blurred, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)

    return scaled

def read_license_plate(model, image_path, conf_threshold=0.25, ocr_conf_threshold=0.5):
    """
    Detect and read license plate from an image using EasyOCR, Tesseract, and PaddleOCR as fallbacks.

    Parameters:
    - model: The YOLO model for license plate detection.
    - image_path: Path to the image file.
    - conf_threshold: Confidence threshold for YOLO detections.
    - ocr_conf_threshold: Confidence threshold for EasyOCR results.

    Returns:
    - text: Detected license plate text or 'UNKNOWN' if all OCR methods fail.
    - plate_img: The cropped license plate image.
    - processed_plate: The preprocessed plate image used for OCR.
    """
    # Read image
    img = cv2.imread(str(image_path))
    if img is None:
        print(f"Error: Unable to read image at {image_path}")
        return "UNKNOWN", None, None
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Detect license plate
    results = model.predict(img_rgb, conf=conf_threshold)[0]

    # Check if any detections are made
    if len(results.boxes) == 0:
        return "UNKNOWN", None, None

    # Extract boxes and confidences
    boxes = results.boxes.xyxy.cpu().numpy()
    confidences = results.boxes.conf.cpu().numpy()
    best_idx = np.argmax(confidences)

    # Get the best box
    box = boxes[best_idx].astype(int)
    conf = confidences[best_idx]

    # Crop license plate with boundary checks
    x1, y1, x2, y2 = box
    x1 = max(x1, 0)
    y1 = max(y1, 0)
    x2 = min(x2, img_rgb.shape[1])
    y2 = min(y2, img_rgb.shape[0])
    plate_img = img_rgb[y1:y2, x1:x2]

    if plate_img.size == 0:
        print(f"Warning: Cropped plate image is empty for {image_path}")
        return "UNKNOWN", plate_img, None

    # Preprocess the plate image
    processed_plate = preprocess_plate(plate_img)

    # Initialize detected text
    text = ''

    # Attempt OCR with EasyOCR
    try:
        ocr_results_easyocr = reader_easyocr.readtext(processed_plate)
        easyocr_text = ' '.join([r[1] for r in ocr_results_easyocr if r[2] >= ocr_conf_threshold])
        easyocr_text_clean = ''.join(c for c in easyocr_text if c.isalnum())
        if easyocr_text_clean:
            text = easyocr_text_clean
            print("OCR Engine Used: EasyOCR")
    except Exception as e:
        print(f"EasyOCR Error: {e}")

    # If EasyOCR fail, fallback to PaddleOCR
    if not text:
        try:
            ocr_results_paddle = reader_paddle.ocr(processed_plate, rec=True, cls=True)
            paddle_text = ' '.join([line[1][0] for line in ocr_results_paddle if line[1][1] >= ocr_conf_threshold])
            paddle_text_clean = ''.join(c for c in paddle_text if c.isalnum())
            if paddle_text_clean:
                text = paddle_text_clean
                print("OCR Engine Used: PaddleOCR")
        except Exception as e:
            print(f"PaddleOCR Error: {e}")

    # If EasyOCR fails, fallback to Tesseract
    if not text:
        try:
            custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
            tesseract_text = pytesseract.image_to_string(processed_plate, config=custom_config)
            tesseract_text_clean = ''.join(c for c in tesseract_text if c.isalnum())
            if tesseract_text_clean:
                text = tesseract_text_clean
                print("OCR Engine Used: Tesseract")
        except Exception as e:
            print(f"Tesseract OCR Error: {e}")


    # If all OCR methods fail, return 'UNKNOWN'
    if not text:
        text = "UNKNOWN"
        print("OCR Failed: Returning 'UNKNOWN'")

    return text, plate_img, processed_plate


def visualize_results(image_path, text, original_plate, processed_plate):
    """
    Visualize original image, cropped plate, processed plate, and OCR result.
    """
    plt.figure(figsize=(15, 4))

    # Original image with plate
    plt.subplot(141)
    img = cv2.imread(str(image_path))
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(img_rgb)
    plt.title('Original Image')
    plt.axis('off')

    # Cropped plate
    plt.subplot(142)
    plt.imshow(original_plate)
    plt.title('Cropped Plate')
    plt.axis('off')

    # Processed plate
    plt.subplot(143)
    plt.imshow(processed_plate, cmap='gray')
    plt.title('Processed Plate')
    plt.axis('off')

    # Text result
    plt.subplot(144)
    plt.text(0.5, 0.5, f'Detected Text:\n{text}',
             ha='center', va='center', fontsize=12,
             bbox=dict(facecolor='white', alpha=0.8))
    plt.axis('off')

    plt.tight_layout()
    plt.show()

# Main execution
if __name__ == "__main__":
    # Load model
    model = YOLO('runs/detect/train5/weights/best.pt')

    # Get test images
    test_dir = Path('/content/drive/MyDrive/License Plates.v3-original-license-plates-test.darknet')
    test_images = list(test_dir.glob('*.jpg'))

    # Process images
    for img_path in test_images:
        print(f"\nProcessing {img_path.name}")

        # Detect and read plate
        text, plate_img, processed_plate = read_license_plate(model, img_path)

        if text is not None:
            print(f"Detected Text: {text}")
            # Visualize results
            visualize_results(img_path, text, plate_img, processed_plate)
        else:
            print("No license plate detected")
